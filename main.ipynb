{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae09933",
   "metadata": {},
   "source": [
    "Academic Honesty Statement\n",
    "\n",
    "> *We declare that this submission is our own work, and that we did not use any pretrained model or code that we did not explicitly cite.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b748d1",
   "metadata": {},
   "source": [
    "## 0. Libraries Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c555857f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n",
      "3.13.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    mean_absolute_error,\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Check keras version\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f7cba",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "### 1.1. Problem Statement\n",
    "The objective of this project is to design, train, and evaluate a Deep Learning model capable of solving a **Multi-task Learning** problem. We are provided with a custom dataset containing **3,000 samples**. Each sample consists of a `(32, 32)` input matrix (interpreted as a grayscale image) associated with three distinct targets:\n",
    "\n",
    "* **Target A:** Classification (10 classes, integers 0-9).\n",
    "* **Target B:** Classification (32 classes, integers 0-31).\n",
    "* **Target C:** Regression (Real value in range $[0, 1]$).\n",
    "\n",
    "### 1.2. Methodology\n",
    "Our goal is to build a **single unified Neural Network** (likely based on CNN) that predicts all three components simultaneously. This approach allows the model to learn shared feature representations from the input images before branching out to specific tasks.\n",
    "\n",
    "The notebook is structured as follows:\n",
    "1.  **Data Inspection:** Analyzing shapes and distributions.\n",
    "2.  **Model Design:** Creating a multi-head architecture.\n",
    "3.  **Experiments:** Tuning hyperparameters (Learning Rate).\n",
    "4.  **Evaluation:** Training the final model and analyzing performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d738f0",
   "metadata": {},
   "source": [
    "# 2. Dataset inspection and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aec9e09",
   "metadata": {},
   "source": [
    "##  2.1. Dataset inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6ca969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "   X Shape: (3000, 32, 32)\n",
      "   y Shape: (3000, 3)\n",
      "\n",
      "--- Raw Data Statistics ---\n",
      "Min Value: 0.0001\n",
      "Max Value: 6.8486\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 2. DATASET INSPECTION\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load the dataset\n",
    "try:\n",
    "    with np.load(\"dataset_dev_3000.npz\") as data:\n",
    "        X_raw = data[\"X\"]\n",
    "        y_raw = data[\"y\"]\n",
    "    print(f\"Dataset loaded successfully.\")\n",
    "    print(f\"   X Shape: {X_raw.shape}\")\n",
    "    print(f\"   y Shape: {y_raw.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"WARNING: 'dataset_dev_3000.npz' not found. Generating dummy data.\")\n",
    "    X_raw = np.random.uniform(0, 7, (3000, 32, 32)).astype(\"float32\")\n",
    "    y_raw = np.column_stack([\n",
    "        np.random.randint(0, 10, 3000), \n",
    "        np.random.randint(0, 32, 3000), \n",
    "        np.random.rand(3000)\n",
    "    ]).astype(\"float32\")\n",
    "\n",
    "# 2. Basic Inspection\n",
    "print(\"\\n--- Raw Data Statistics ---\")\n",
    "print(f\"Min Value: {X_raw.min():.4f}\")\n",
    "print(f\"Max Value: {X_raw.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfffb28",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "\n",
    "Value Range: The input values range from **0.0001 to 6.8486**. This is a non-standard range for image data (typically [0-255] or [0-1]). Feeding this directly into a Neural Network may lead to unstable gradients. Therefore, Normalization (scaling to [0,1] or standardization) is a mandatory preprocessing step before training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6cc37",
   "metadata": {},
   "source": [
    "## 2.2. Data visualisation\n",
    "\n",
    "### Description\n",
    "\n",
    "We will visually inspect the input images conditioned on each target:\n",
    "\n",
    "- **Target A (10-class)**: sample a small grid of images per class label (0–9).\n",
    "- **Target B (32-class)**: sample one image per label (0–31) to quickly see intra-class consistency / ambiguity.\n",
    "- **Target C (regression)**: bin continuous values into quantile ranges and sample images from low → mid → high bins to see if any visible signal tracks the regression target.\n",
    "\n",
    "This helps validate label sanity and gives intuition for model difficulty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de65f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3.1. VISUALISE SAMPLES BY TARGET LABELS\n",
    "# ==========================================\n",
    "\n",
    "# 1) Prepare labels\n",
    "yA = y_raw[:, 0].astype(np.int32)\n",
    "yB = y_raw[:, 1].astype(np.int32)\n",
    "yC = y_raw[:, 2].astype(np.float32)\n",
    "\n",
    "rng = np.random.RandomState(41)\n",
    "\n",
    "\n",
    "def plot_grid(\n",
    "    images,\n",
    "    titles=None,\n",
    "    nrows=4,\n",
    "    ncols=8,\n",
    "    figsize=(12, 6),\n",
    "    suptitle=None,\n",
    "    cmap=\"viridis\",\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "):\n",
    "    \"\"\"Plot a grid of 2D arrays using a colormap (false color).\"\"\"\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.axis(\"off\")\n",
    "        if i >= len(images):\n",
    "            continue\n",
    "        ax.imshow(images[i], cmap=cmap, vmin=vmin, vmax=vmax, interpolation=\"nearest\")\n",
    "        if titles is not None:\n",
    "            ax.set_title(str(titles[i]), fontsize=8)\n",
    "\n",
    "    if suptitle is not None:\n",
    "        fig.suptitle(suptitle, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 3.1 VISUALISE SAMPLES - TARGET A ---\")\n",
    "# --------------------------\n",
    "# Target A: K samples/class\n",
    "# --------------------------\n",
    "n_per_class_a = 5\n",
    "imgs_a = []\n",
    "titles_a = []\n",
    "\n",
    "for cls in range(10):\n",
    "    idx = np.where(yA == cls)[0]\n",
    "    if len(idx) == 0:\n",
    "        continue\n",
    "    pick = rng.choice(idx, size=min(n_per_class_a, len(idx)), replace=False)\n",
    "    for j in pick:\n",
    "        imgs_a.append(X_raw[j])\n",
    "        titles_a.append(f\"A={cls}\")\n",
    "\n",
    "plot_grid(\n",
    "    imgs_a,\n",
    "    titles=titles_a,\n",
    "    nrows=10,\n",
    "    ncols=n_per_class_a,\n",
    "    figsize=(2.0 * n_per_class_a, 18),\n",
    "    suptitle=\"Target A: sample images per class\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 3.1 VISUALISE SAMPLES - TARGET B ---\")\n",
    "# --------------------------\n",
    "# Target B: 1 sample/label\n",
    "# --------------------------\n",
    "imgs_b = []\n",
    "titles_b = []\n",
    "\n",
    "for cls in range(32):\n",
    "    idx = np.where(yB == cls)[0]\n",
    "    if len(idx) == 0:\n",
    "        imgs_b.append(np.zeros((32, 32), dtype=np.float32))\n",
    "        titles_b.append(f\"B={cls} (missing)\")\n",
    "        continue\n",
    "    j = rng.choice(idx, size=1, replace=False)[0]\n",
    "    imgs_b.append(X_raw[j])\n",
    "    titles_b.append(f\"B={cls}\")\n",
    "\n",
    "plot_grid(\n",
    "    imgs_b,\n",
    "    titles=titles_b,\n",
    "    nrows=4,\n",
    "    ncols=8,\n",
    "    figsize=(16, 8),\n",
    "    suptitle=\"Target B: one sample per label (0–31)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80de97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 3.1 VISUALISE SAMPLES - TARGET C ---\")\n",
    "# --------------------------\n",
    "# Target C: quantile bins\n",
    "# --------------------------\n",
    "q_edges = np.quantile(yC, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "bin_id = np.digitize(yC, q_edges[1:-1], right=True)  # 0..4\n",
    "\n",
    "imgs_c = []\n",
    "titles_c = []\n",
    "n_per_bin = 6\n",
    "\n",
    "for b in range(5):\n",
    "    idx = np.where(bin_id == b)[0]\n",
    "    if len(idx) == 0:\n",
    "        continue\n",
    "    pick = rng.choice(idx, size=min(n_per_bin, len(idx)), replace=False)\n",
    "    lo, hi = q_edges[b], q_edges[b + 1]\n",
    "    for j in pick:\n",
    "        imgs_c.append(X_raw[j])\n",
    "        titles_c.append(f\"C in [{lo:.3f},{hi:.3f}]\")\n",
    "\n",
    "plot_grid(\n",
    "    imgs_c,\n",
    "    titles=titles_c,\n",
    "    nrows=5,\n",
    "    ncols=n_per_bin,\n",
    "    figsize=(2.0 * n_per_bin, 10),\n",
    "    suptitle=\"Target C: sample images across quantile bins\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c33dc",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "- **Target A**: Samples across the 10 classes exhibit highly similar structure. Most images are dominated by a strong central peak and axis-aligned streaks, with no clearly distinguishable class-specific visual patterns.\n",
    "- **Target B**: Across the 32 labels, the visual appearance remains largely consistent and dominated by the same shared structure. Any differences appear subtle and inconsistent, suggesting limited separability from direct visual inspection.\n",
    "- **Target C**: Across quantile bins, the images remain visually similar and dominated by the same shared artifact. No clear monotonic visual trend is observed from low to high Target C values in this qualitative view.\n",
    "\n",
    "**Reflection**: Overall, the dataset does not present strong label-specific features that are obvious to manual inspection. This suggests that discriminative information (if present) is subtle and must be learned through feature extraction, motivating the use of a sufficiently expressive CNN trunk and careful regularization/preprocessing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c444001a",
   "metadata": {},
   "source": [
    "## 2.3. Label imbalance check\n",
    "\n",
    "### Description\n",
    "\n",
    "We will quickly check if the dataset is imbalanced:\n",
    "\n",
    "- **Target A**: class counts (0–9) and imbalance ratio.\n",
    "- **Target B**: class counts (0–31) and imbalance ratio.\n",
    "- **Target C**: distribution summary (histogram + percentiles). _(Not “imbalance” per se, but we check if it is skewed or concentrated.)_\n",
    "\n",
    "This informs whether we need class weighting, focal loss, sampling strategies, or special metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3.2. LABEL IMBALANCE CHECK\n",
    "# ==========================================\n",
    "\n",
    "print(\"--- 3.2 LABEL IMBALANCE CHECK ---\")\n",
    "\n",
    "# Target A\n",
    "counts_a = np.bincount(yA, minlength=10)\n",
    "print(\"Target A counts:\", counts_a)\n",
    "print(\n",
    "    \"Target A imbalance ratio (max/min nonzero):\",\n",
    "    counts_a.max() / counts_a[counts_a > 0].min(),\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.bar(np.arange(10), counts_a)\n",
    "plt.title(\"Target A: class counts (0–9)\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Target B\n",
    "counts_b = np.bincount(yB, minlength=32)\n",
    "print(\"Target B counts:\", counts_b)\n",
    "print(\n",
    "    \"Target B imbalance ratio (max/min nonzero):\",\n",
    "    counts_b.max() / counts_b[counts_b > 0].min(),\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 3))\n",
    "plt.bar(np.arange(32), counts_b)\n",
    "plt.title(\"Target B: class counts (0–31)\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Target C\n",
    "pct = np.percentile(yC, [0, 1, 5, 25, 50, 75, 95, 99, 100])\n",
    "print(\"Target C percentiles [0,1,5,25,50,75,95,99,100]:\", np.round(pct, 4))\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.hist(yC, bins=30, color=\"purple\", alpha=0.7)\n",
    "plt.title(\"Target C: distribution (histogram)\")\n",
    "plt.xlabel(\"y[:,2]\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db81131f",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "- **Target A**: The label distribution is highly uniform across the 10 classes. Counts range from 290 to 311, yielding a low imbalance ratio (max/min nonzero) of **1.0724**. This suggests class imbalance is unlikely to be a major driver of performance differences for Target A.\n",
    "\n",
    "- **Target B**: The 32-class distribution is also relatively even. Counts range from 75 to 113, with an imbalance ratio (max/min nonzero) of **1.5067**. A few classes are approximately **15% below the average** frequency, but there are no extreme rare or missing classes.\n",
    "\n",
    "- **Target C**: The regression target is broadly well-distributed across \\([0, 1]\\). The median is approximately **0.4984** and the interquartile range spans roughly **0.2524 to 0.7361**. The tails are present but not excessively concentrated (95th percentile ≈ **0.9501**, 99th percentile ≈ **0.9898**), indicating no strong skew toward a narrow range.\n",
    "\n",
    "**Reflection**: Since Targets A and B are close to uniformly distributed and Target C is not strongly skewed, imbalance is unlikely to be the primary bottleneck. If a target has a low performance, it is more likely due to limited separable signal or task difficulty rather than label frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8901f53",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing\n",
    "\n",
    "### 3.1. Train/validation split strategy\n",
    "To maximize the amount of data available for training while ensuring a fair evaluation, we updated our splitting strategy with `random_state=32` for reproducibility. We employed a **two-stage split**:\n",
    "\n",
    "1.  **Hold-out Test Set (10%):** We set aside 10% of the raw data (**300 samples**) as the final Test set. This set is strictly isolated and used only for the final evaluation.\n",
    "2.  **Train / Validation Split (90/10 of remaining):** From the remaining 2,700 samples, we split further:\n",
    "    * **Validation Set:** 10% of the remaining data (~**270 samples**) to monitor overfitting during training.\n",
    "    * **Training Set:** The remaining ~**2,430 samples**.\n",
    "\n",
    "**Final Data Distribution:**\n",
    "* **Training:** 2,430 samples (~81%) $\\rightarrow$ *Increased to improve model learning.*\n",
    "* **Validation:** 270 samples (~9%)\n",
    "* **Test:** 300 samples (~10%)\n",
    "\n",
    "### 3.2. Preprocessing: Normalization & Reshaping\n",
    "Based on the data inspection, we applied the following transformations to prepare inputs for the CNN:\n",
    "\n",
    "1.  **Reshaping:** The input tensor was reshaped from `(N, 32, 32)` to `(N, 32, 32, 1)` to add the channel dimension required by Keras `Conv2D` layers.\n",
    "2.  **Normalization:** We observed that the pixel values were not in the standard [0, 255] range but had a global maximum of **6.8486**. We normalized the data to the range **$[0, 1]$** using the formula:\n",
    "    $$X_{norm} = \\frac{X}{6.8486}$$\n",
    "    \n",
    "    * **Train Norm Range:** $[0.000, 1.000]$\n",
    "    * This ensures stable gradient descent and faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af72720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: (2430, 32, 32)\n",
      "Val Set:   (270, 32, 32)\n",
      "Test Set:  (300, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3.1. TRAIN/VALIDATION SPLIT STRATEGY\n",
    "# ==========================================\n",
    "\n",
    "# Split 1: Separate Test set (10%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.1, random_state=32\n",
    ")\n",
    "\n",
    "# Split 2: Separate Validation set (10% of remaining)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.1, random_state=32\n",
    ")\n",
    "\n",
    "print(f\"Train Set: {X_train.shape}\")\n",
    "print(f\"Val Set:   {X_val.shape}\")\n",
    "print(f\"Test Set:  {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa40a289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DATA PREPARATION ---\n",
      "Global Max found in training data: 6.8486\n",
      "Train Norm Shape: (2430, 32, 32, 1) (Rank-4)\n",
      "Train Norm Range: [0.000, 1.000]\n",
      "Data preparation complete.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3.2. DATA PREPARATION & NORMALIZATION\n",
    "# ==========================================\n",
    "print(\"--- DATA PREPARATION ---\")\n",
    "\n",
    "# 1. Calculate Global Max from Training Data\n",
    "GLOBAL_MAX = float(X_train.max())\n",
    "print(f\"Global Max found in training data: {GLOBAL_MAX:.4f}\")\n",
    "\n",
    "# 2. Reshape & Normalize\n",
    "# Add channel dimension: (N, 32, 32) -> (N, 32, 32, 1)\n",
    "# Normalize to range [0, 1] using Global Max\n",
    "X_train_norm = X_train.reshape((-1, 32, 32, 1)).astype(\"float32\") / GLOBAL_MAX\n",
    "X_val_norm = X_val.reshape((-1, 32, 32, 1)).astype(\"float32\") / GLOBAL_MAX\n",
    "X_test_norm = X_test.reshape((-1, 32, 32, 1)).astype(\"float32\") / GLOBAL_MAX\n",
    "\n",
    "# Verify shapes and ranges\n",
    "print(f\"Train Norm Shape: {X_train_norm.shape} (Rank-4)\")\n",
    "print(f\"Train Norm Range: [{X_train_norm.min():.3f}, {X_train_norm.max():.3f}]\")\n",
    "\n",
    "# 3. Split Targets for Multi-Output Model\n",
    "y_train_A, y_train_B, y_train_C = y_train[:, 0], y_train[:, 1], y_train[:, 2]\n",
    "y_val_A, y_val_B, y_val_C = y_val[:, 0], y_val[:, 1], y_val[:, 2]\n",
    "y_test_A, y_test_B, y_test_C = y_test[:, 0], y_test[:, 1], y_test[:, 2]\n",
    "\n",
    "print(\"Data preparation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7552d07",
   "metadata": {},
   "source": [
    "###  Data Augmentation Strategy\n",
    "\n",
    "Given the limited dataset size (3,000 samples), overfitting is a significant concern where the model might memorize training examples instead of learning general features. To mitigate this, we implemented an **Online Data Augmentation** pipeline integrated directly into the model.\n",
    "\n",
    "We selected specific transformations suited for low-resolution images ($32 \\times 32$):\n",
    "\n",
    "1.  **RandomFlip (\"horizontal\"):** * Simulates mirror reflections. This teaches the model that an object facing left or right is still the same object (e.g., a car or animal).\n",
    "    \n",
    "2.  **RandomTranslation (0.05, 0.05):** * Shifts the image horizontally and vertically by up to 5%.\n",
    "    * *Reasoning:* In real-world data, objects are not always perfectly centered. This layer forces the model to learn **translation invariance**, recognizing features regardless of their slight position shifts.\n",
    "\n",
    "3.  **RandomRotation (0.05):** * Rotates the image by approximately $18^\\circ$ (5% of a full circle).\n",
    "    * *Reasoning:* We kept the rotation factor small (`0.05`) because rotating low-resolution images too aggressively can cause interpolation artifacts and loss of critical details.\n",
    "\n",
    "*Note: These layers are active only during training (`training=True`) and are automatically disabled during validation and testing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cb81049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BUILDING TF.DATA PIPELINE ---\n",
      "   Augmentation layers initialized.\n",
      "Data Pipeline Ready.\n",
      " Train Batches: 76\n",
      " Val Batches:   9\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# DATA AUGMENTATION & PIPELINE\n",
    "# ==========================================\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"--- BUILDING TF.DATA PIPELINE ---\")\n",
    "\n",
    "# 1. Define Data Augmentation Policy\n",
    "# Note: Using standard geometric augmentations.\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomTranslation(0.05, 0.05),\n",
    "    layers.RandomRotation(0.05),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "print(\"   Augmentation layers initialized.\")\n",
    "\n",
    "# 2. Create Train Dataset\n",
    "# Wrap tensors into a tf.data.Dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (X_train_norm, (y_train_A, y_train_B, y_train_C))\n",
    ")\n",
    "\n",
    "def train_map(x, y):\n",
    "    \"\"\"\n",
    "    Apply augmentation to the input image batch during training.\n",
    "    training=True ensures augmentation is active.\n",
    "    \"\"\"\n",
    "    x = data_augmentation(x, training=True)\n",
    "    return x, y\n",
    "\n",
    "# Configure pipeline: Shuffle -> Map (Augment) -> Batch -> Prefetch\n",
    "train_ds = (\n",
    "    train_ds\n",
    "    .shuffle(1024)\n",
    "    .map(train_map, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(32)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# 3. Create Validation Dataset\n",
    "# No augmentation for validation, just batching\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (X_val_norm, (y_val_A, y_val_B, y_val_C))\n",
    ").batch(32).prefetch(tf.data.AUTOTUNE) # Added prefetch for speed\n",
    "\n",
    "print(\"Data Pipeline Ready.\")\n",
    "print(f\" Train Batches: {len(train_ds)}\")\n",
    "print(f\" Val Batches:   {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66796ca",
   "metadata": {},
   "source": [
    "# 4. Model architecture reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6237840",
   "metadata": {},
   "source": [
    "###  Residual Block Architecture\n",
    "\n",
    "- The core building unit of the proposed model is a residual block designed to preserve low-level features while learning higher-level representations.\n",
    "\n",
    "- Structure: Consists of two consecutive 3×3 convolutional layers, each followed by Batch Normalization.\n",
    "\n",
    "- Activation: The first convolution is followed by a ReLU activation, while the second omits it until after the residual addition.\n",
    "\n",
    "- Shortcut Connection: An identity path bypasses the convolutional layers and is added element-wise to the output, improving convergence and generalization.\n",
    "\n",
    "- Adaptation: When spatial resolution or channel dimensionality changes, the shortcut uses a 1×1 convolution with an appropriate stride to maintain mathematical consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed418879",
   "metadata": {},
   "source": [
    "### CIFAR-Style ResNet Trunk\n",
    "\n",
    "- The model adopts a specialized ResNet design tailored for small input images (32×32 pixels), avoiding the aggressive early downsampling found in standard ImageNet architectures.\n",
    "\n",
    "- Lightweight Stem: Begins with a simple 3×3 convolutional stem rather than large kernels.\n",
    "\n",
    "- Hierarchical Stages: The trunk is organized into three stages with increasing filter depths (32, 64, and 128), capturing features ranging from local textures to abstract patterns.\n",
    "\n",
    "- Gradual Downsampling: Performed using stride-2 convolutions within the residual blocks to preserve spatial information critical for low-resolution inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da3874",
   "metadata": {},
   "source": [
    "### Global Feature Aggregation\n",
    "\n",
    "- Following the convolutional trunk, the model utilizes Global Average Pooling to process the feature maps.\n",
    "\n",
    "- Dimensionality Reduction: Collapses spatial dimensions, drastically reducing the number of trainable parameters compared to traditional flattening.\n",
    "\n",
    "- Regularization: Acts as a strong regularizer by forcing the network to encode spatially invariant, semantically meaningful features.\n",
    "\n",
    "- Overfitting Prevention: Specifically beneficial for small datasets where full dense layers might lead to memorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eabb66",
   "metadata": {},
   "source": [
    "### Shared Representation and Regularization\n",
    "\n",
    "- The pooled features feed into a shared fully connected layer that acts as the central hub for multi-task learning.\n",
    "\n",
    "- Latent Representation: Produces a compact feature vector used by all subsequent task-specific heads.\n",
    "\n",
    "- Stabilization: Incorporates Batch Normalization and ReLU activation to improve training stability and non-linearity.\n",
    "\n",
    "- Dropout: Applies random neuron deactivation during training to further reduce the risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076b0b93",
   "metadata": {},
   "source": [
    "### Multi-Head Output Design\n",
    "\n",
    "- The network branches into three specialized output heads, allowing the model to learn both shared and task-specific representations effectively.\n",
    "\n",
    "- Classification Heads: Two distinct heads produce probability distributions over 10 classes and 32 classes respectively, utilizing Softmax activation.\n",
    "\n",
    "- Regression Head: A third head outputs a continuous value using Linear activation.\n",
    "\n",
    "- Head Architecture: Each head contains task-specific dense layers equipped with Batch Normalization, ReLU, and Dropout to ensure sufficient capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81de8fb4",
   "metadata": {},
   "source": [
    "**Residual Block Architecture**\n",
    "\n",
    "The core building unit of the proposed model is a residual block, which consists of two consecutive 3×3 convolutional layers followed by batch normalization. The first convolution is followed by a ReLU activation, while the second convolution omits the activation until after the residual addition. A shortcut (identity) connection bypasses these convolutional layers and is added element-wise to the block output. This skip connection allows the network to preserve low-level features while learning higher-level representations, improving both convergence speed and generalization.\n",
    "\n",
    "When spatial resolution or channel dimensionality changes, the shortcut path is adapted using a 1×1 convolution with appropriate stride. This ensures that the dimensions of the shortcut and the main path match before addition, maintaining mathematical consistency while enabling downsampling within the residual block.\n",
    "\n",
    "**CIFAR-Style ResNet Trunk**\n",
    "\n",
    "The model adopts a CIFAR-style ResNet design, which is specifically tailored for small input images (32×32 pixels). Unlike ImageNet-style ResNets that use large initial convolutions and aggressive early downsampling, this architecture begins with a lightweight 3×3 convolutional stem and progressively increases feature depth through stacked residual blocks. Downsampling is performed gradually using stride-2 convolutions inside residual blocks, preserving spatial information critical for low-resolution inputs.\n",
    "\n",
    "The trunk is organized into three stages with increasing numbers of filters (32, 64, and 128), allowing the network to capture hierarchical features ranging from local textures to more abstract patterns. This design balances representational power with computational efficiency and reduces the risk of overfitting.\n",
    "\n",
    "**Global Feature Aggregation**\n",
    "\n",
    "Following the convolutional trunk, Global Average Pooling is applied to collapse the spatial dimensions of the feature maps. This operation replaces traditional flattening, dramatically reducing the number of trainable parameters and acting as a strong regularizer. Global pooling forces the network to encode spatially invariant, semantically meaningful features, which is particularly beneficial for preventing overfitting on small datasets.\n",
    "\n",
    "**Shared Representation and Regularization**\n",
    "\n",
    "The pooled features are passed through a shared fully connected layer that produces a compact latent representation used by all task-specific heads. Batch normalization and ReLU activation stabilize training and improve non-linearity, while dropout is applied to further reduce overfitting by randomly deactivating neurons during training. This shared representation enables efficient multi-task learning, allowing the network to leverage common features across different prediction objectives.\n",
    "\n",
    "**Multi-Head Output Design**\n",
    "\n",
    "The architecture employs three specialized output heads, each optimized for a different task. Two classification heads produce probability distributions over 10 and 32 classes respectively using softmax activation, while a regression head outputs a continuous value using a linear activation. Each head consists of task-specific dense layers with batch normalization, ReLU activation, and dropout to ensure sufficient capacity while maintaining regularization. This design allows the model to learn both shared and task-specific representations effectively within a unified framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71437a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ img_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ img_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,216</span> │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,216</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,216</span> │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,216</span> │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,728</span> │ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │                   │            │ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ out_a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ out_b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ out_c (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ img_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m288\u001b[0m │ img_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m9,216\u001b[0m │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m9,216\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m9,216\u001b[0m │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m9,216\u001b[0m │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │     \u001b[38;5;34m18,432\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │     \u001b[38;5;34m36,864\u001b[0m │ re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │     \u001b[38;5;34m36,864\u001b[0m │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │     \u001b[38;5;34m36,864\u001b[0m │ re_lu_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m73,728\u001b[0m │ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,456\u001b[0m │ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │      \u001b[38;5;34m8,192\u001b[0m │ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,456\u001b[0m │ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,456\u001b[0m │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │                   │            │ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,384\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,192\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,192\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m4,096\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m128\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ out_a (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ out_b (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ out_c (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">737,771</span> (2.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m737,771\u001b[0m (2.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">734,955</span> (2.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m734,955\u001b[0m (2.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> (11.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,816\u001b[0m (11.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4.1. MODEL DEFINITION\n",
    "# ==========================================\n",
    "def residual_block(x, filters, downsample=False):\n",
    "    stride = 2 if downsample else 1\n",
    "    shortcut = x\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, strides=stride, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Match dimensions if needed\n",
    "    if downsample or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=stride, use_bias=False)(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    inputs = keras.Input(shape=(32, 32, 1), name=\"img_input\")\n",
    "\n",
    "    # Stem\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", use_bias=False)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # ResNet stages\n",
    "    x = residual_block(x, 32)\n",
    "    x = residual_block(x, 32)\n",
    "\n",
    "    x = residual_block(x, 64, downsample=True)\n",
    "    x = residual_block(x, 64)\n",
    "\n",
    "    x = residual_block(x, 128, downsample=True)\n",
    "    x = residual_block(x, 128)\n",
    "\n",
    "    # Global pooling\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Shared feature layer\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    features = x\n",
    "\n",
    "    # =============================\n",
    "    # Heads\n",
    "    # =============================\n",
    "\n",
    "    # Head A\n",
    "    a = layers.Dense(64, use_bias=False)(features)\n",
    "    a = layers.BatchNormalization()(a)\n",
    "    a = layers.ReLU()(a)\n",
    "    a = layers.Dropout(0.3)(a)\n",
    "    out_a = layers.Dense(10, activation=\"softmax\", name=\"out_a\")(a)\n",
    "\n",
    "    # Head B\n",
    "    b = layers.Dense(64, use_bias=False)(features)\n",
    "    b = layers.BatchNormalization()(b)\n",
    "    b = layers.ReLU()(b)\n",
    "    b = layers.Dropout(0.3)(b)\n",
    "    out_b = layers.Dense(32, activation=\"softmax\", name=\"out_b\")(b)\n",
    "\n",
    "    # Head C\n",
    "    c = layers.Dense(32, use_bias=False)(features)\n",
    "    c = layers.BatchNormalization()(c)\n",
    "    c = layers.ReLU()(c)\n",
    "    c = layers.Dropout(0.2)(c)\n",
    "    out_c = layers.Dense(1, activation=\"linear\", name=\"out_c\")(c)\n",
    "\n",
    "    return keras.Model(inputs, [out_a, out_b, out_c])\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b3c0eb",
   "metadata": {},
   "source": [
    "### Experimental Setup\n",
    "\n",
    "- Optimizer: **Adam** \n",
    "\n",
    "- Learning Rate: Set to 0.001. This value provides adaptive learning rates for parameters, ensuring stable convergence for the deep neural network structure without oscillating or getting stuck in local minima.\n",
    "\n",
    "### Loss Functions and Balancing\n",
    "\n",
    "To handle the multi-task nature of the problem, the model minimizes a weighted sum of three distinct loss functions.\n",
    "\n",
    "- Classification Losses: Sparse Categorical Cross-entropy is used for both the 10-class and 32-class outputs, suitable for integer-encoded targets.\n",
    "\n",
    "- Regression Loss: Mean Squared Error (MSE) is employed for the continuous regression output.\n",
    "\n",
    "- Loss Weighting: Weights of [1.0, 1.0, 0.1] are applied respectively. The regression weight is set to 0.1 to scale the MSE (which can have larger magnitude) down to a range comparable with the cross-entropy losses, preventing the regression task from dominating the total gradient updates.\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "Performance is monitored using task-appropriate metrics that provide interpretable feedback during training.\n",
    "\n",
    "- Accuracy: Used for the two classification heads to measure the percentage of correct predictions.\n",
    "\n",
    "- Mean Absolute Error (MAE): Used for the regression head to measure the average magnitude of errors in the predicted values, providing a clear intuitive sense of model precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7823848",
   "metadata": {},
   "source": [
    "The model was compiled using the Adam optimizer with a learning rate of 0.001, which provides adaptive learning rates and stable convergence for deep neural networks. Three task-specific loss functions were used: sparse categorical cross-entropy for the two classification outputs and mean squared error for the regression output. To balance multi-task learning, loss weights of 1.0, 1.0, and 0.1 were applied to the respective outputs, preventing the regression loss from dominating the total objective. Model performance was monitored using accuracy for classification tasks and mean absolute error for the regression task, providing interpretable and task-appropriate evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c69d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4.2. COMPILATION\n",
    "# ==========================================\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss={\n",
    "        \"out_a\": \"sparse_categorical_crossentropy\",\n",
    "        \"out_b\": \"sparse_categorical_crossentropy\",\n",
    "        \"out_c\": \"mse\",\n",
    "    },\n",
    "    loss_weights=[1.0, 1.0, 0.1],\n",
    "    metrics={\"out_a\": \"accuracy\", \"out_b\": \"accuracy\", \"out_c\": \"mae\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67426a93",
   "metadata": {},
   "source": [
    "### Training Strategy\n",
    "\n",
    "The training process is rigorously controlled to maximize generalization and ensure convergence using adaptive mechanisms.\n",
    "\n",
    "- Execution & Validation: The model is trained for a maximum of 100 epochs. A dedicated validation dataset is used to monitor performance at the end of each epoch, strictly separating training data from evaluation data.\n",
    "\n",
    "- Model Checkpointing: A ModelCheckpoint callback is employed to automatically save the model weights corresponding to the minimum validation loss. This guarantees that the final retained model represents the optimal performance point, rather than the state at the arbitrary final epoch.\n",
    "\n",
    "- Adaptive Learning Rate: To handle training plateaus, a ReduceLROnPlateau callback is applied. If the validation loss fails to improve for 20 consecutive epochs, the learning rate is reduced by a factor of 0.5. This allows the model to refine its solution with smaller steps in later stages.\n",
    "\n",
    "- Robustness: These callbacks collectively provide optimization control, preventing premature convergence and ensuring the model remains robust without overfitting to the training noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920190e3",
   "metadata": {},
   "source": [
    "The model was trained using a maximum of 100 epochs with validation performance monitored at the end of each epoch. Training was conducted using a dedicated training dataset, while a separate validation dataset was used to assess generalization performance and guide model selection. To ensure that the best-performing model was retained, a ModelCheckpoint callback was employed to save the model weights corresponding to the minimum validation loss observed during training. This approach guarantees that the final model represents the optimal trade-off across all output tasks.\n",
    "\n",
    "To improve training stability and convergence, a ReduceLROnPlateau callback was applied. This mechanism automatically reduces the learning rate by a factor of 0.5 when validation loss fails to improve for 20 consecutive epochs. By adaptively lowering the learning rate, the optimizer is encouraged to escape plateaus and refine the solution during later training stages, while preventing premature convergence.\n",
    "\n",
    "Together, these callbacks provide effective regularization and optimization control, reducing the risk of overfitting and improving overall model robustness. The combination of extended training duration, adaptive learning rate adjustment, and validation-based checkpointing ensures that the model converges efficiently while maintaining strong generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d46d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4.3. TRAINING\n",
    "# ==========================================\n",
    "print(\"\\n--- 3. STARTING TRAINING ---\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.h5\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "\n",
    "    # If LR is small, progress per epoch can be slow/noisy; let it run longer and\n",
    "    # optionally auto-reduce LR on plateaus before giving up.\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.5,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        min_lr=1e-4,\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=100,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ede8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4.4. PREDICT FUNCTION\n",
    "# ==========================================\n",
    "def predict_fn(X_raw):\n",
    "    # 1. Reshape\n",
    "    # 2. Normalize\n",
    "    X_proc = X_raw.reshape((-1, 32, 32, 1)).astype(\"float32\") / GLOBAL_MAX\n",
    "\n",
    "    # 3. Predict\n",
    "    model = keras.models.load_model(\"best_model.h5\", compile=False)\n",
    "    pred_probs_a, pred_probs_b, pred_c_val = model.predict(X_proc, verbose=0)\n",
    "\n",
    "    # 4. Process\n",
    "    pred_a = np.argmax(pred_probs_a, axis=1)\n",
    "    pred_b = np.argmax(pred_probs_b, axis=1)\n",
    "    pred_c = pred_c_val.flatten()\n",
    "\n",
    "    # 5. Stack\n",
    "    return np.column_stack([pred_a, pred_b, pred_c])\n",
    "\n",
    "\n",
    "# print(\"\\n--- CHECKING PREDICT_FN ---\")\n",
    "# sample_preds = predict_fn(X_val[:5])\n",
    "# print(\"Output Shape:\", sample_preds.shape)\n",
    "# print(\"Sample Predictions:\\n\", sample_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f71488",
   "metadata": {},
   "source": [
    "### Experimental Results\n",
    "\n",
    "**Target A** : 10-Class Classification (Digits 0–9)\n",
    "\n",
    "- The testing results show an overall accuracy of 37% for the digit classification task, with varying performance across specific classes.\n",
    "\n",
    "- Metric Overview: Macro-averaged precision, recall, and F1-scores are all consistent at approximately 0.35.\n",
    "\n",
    "- Class Sensitivity: Digits 6, 5, and 9 exhibit higher recall and F1-scores, indicating easier identification. Conversely, digits 0, 3, and 7 show substantially lower recall.\n",
    "\n",
    "- Error Analysis: The confusion matrix confirms that misclassifications mostly occur between visually similar classes, an expected outcome given the low-resolution grayscale inputs and limited data.\n",
    "\n",
    "**Target B** : 32-Class Classification\n",
    "\n",
    "- Performance for the 32-class output is significantly weaker, reflecting the high difficulty of this task relative to the dataset size.\n",
    "\n",
    "- Low Accuracy: The model achieves only 5% accuracy with a macro-averaged F1-score of 0.03.\n",
    "\n",
    "- Class Collapse: Many classes record zero precision and recall, indicating a failure to predict these labels entirely.\n",
    "\n",
    "-  Complexity Issues: The combination of high class cardinality (32) and shared feature representations limits discriminative capacity. Predictions are concentrated in a small subset of classes rather than being distributed across the full range.\n",
    "\n",
    "**Target C** : Regression\n",
    "\n",
    "- In contrast to the classification tasks, the regression head demonstrates more stable behavior.\n",
    "\n",
    "- Correlation: The true-versus-predicted scatter plot shows a general positive correlation between the model's output and ground truth values.\n",
    "\n",
    "- Performance: Mean Absolute Error (MAE) indicates moderate predictive accuracy.\n",
    "\n",
    "- Deviations: While the general trend is captured, predictions tend to deviate from the ideal diagonal line near the extreme values. However, this head benefits from the smoother loss landscape of the shared backbone.\n",
    "\n",
    "**Conclusion**  \n",
    "\n",
    "Overall, the model learns coarse visual representations sufficient for simpler tasks but struggles with fine-grained multi-class discrimination.\n",
    "\n",
    "- Key Findings: The shared architecture works for regression and basic classification but lacks capacity for the complex 32-class target.\n",
    "\n",
    "- Future Improvements: These results motivate the implementation of data augmentation, class balancing, deeper architectures, or task-specific feature separation in future iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0f2151",
   "metadata": {},
   "source": [
    "The testing results highlight clear differences in performance across the three prediction tasks, reflecting the varying levels of difficulty and data complexity associated with each output head. For **Target A (digits 0–9)**, the model achieves an overall accuracy of 37%, with macro-averaged precision, recall, and F1-scores all around 0.35. Performance varies notably across individual classes. Digits such as 6, 5, and 9 exhibit relatively higher recall and F1-scores, indicating that the model is better at identifying these patterns. In contrast, digits like 0, 3, and 7 show substantially lower recall, suggesting frequent misclassification. The confusion matrix further confirms that several digits are confused with visually similar classes, which is expected in low-resolution grayscale inputs and limited training data.\n",
    "\n",
    "For **Target B (32-class classification)**, performance is considerably weaker, with an overall accuracy of only 5% and macro-averaged F1-score of 0.03. Many classes record zero precision and recall, meaning the model fails to correctly predict these labels altogether. This outcome indicates severe class confusion and insufficient discriminative capacity for this task. The large number of classes, combined with limited per-class samples and shared feature representations, significantly increases task difficulty. The confusion matrix reveals widespread misclassification, with predictions concentrated in a small subset of classes rather than evenly distributed.\n",
    "\n",
    "In contrast, **Target C (regression)** demonstrates more stable behavior. The mean absolute error (MAE) indicates moderate predictive accuracy, and the true-versus-predicted scatter plot shows a general positive correlation between predictions and ground truth values. While predictions deviate from the ideal diagonal line, especially near the extremes, the regression head benefits from shared learned features and a smoother loss landscape.\n",
    "\n",
    "Overall, the results suggest that the model learns coarse visual representations sufficient for simpler classification and regression tasks, but struggles with fine-grained multi-class discrimination. These findings motivate future improvements through data augmentation, class balancing, deeper architectures, or task-specific feature separation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c3f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4.5. EVALUATION & VISUALIZATION\n",
    "# ==========================================\n",
    "print(\"\\n--- 4. EVALUATION & PLOTS ---\")\n",
    "\n",
    "# 1. Generate Predictions on Test Set\n",
    "# We use the predict_fn wrapper which handles shaping/normalization automatically\n",
    "print(\"Generating predictions for Test Set...\")\n",
    "val_preds = predict_fn(X_test)\n",
    "\n",
    "# Extract components from the stacked predictions\n",
    "# pred_a/b are class indices (integers), pred_c is float\n",
    "pred_a = val_preds[:, 0].astype(int)\n",
    "pred_b = val_preds[:, 1].astype(int)\n",
    "pred_c = val_preds[:, 2]\n",
    "\n",
    "# --- Target A (Classification 0-9) ---\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"TARGET A (Digits 0-9) PERFORMANCE\")\n",
    "print(\"=\" * 40)\n",
    "print(classification_report(y_test_A, pred_a))\n",
    "\n",
    "# Plot Confusion Matrix for A\n",
    "fig_a, ax_a = plt.subplots(figsize=(8, 8))\n",
    "cm_a = confusion_matrix(y_test_A, pred_a)\n",
    "disp_a = ConfusionMatrixDisplay(confusion_matrix=cm_a, display_labels=np.arange(10))\n",
    "disp_a.plot(cmap=plt.cm.Blues, ax=ax_a)\n",
    "ax_a.set_title(\"Target A: Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# --- Target B (Classification 0-31) ---\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"TARGET B (Classes 0-31) PERFORMANCE\")\n",
    "print(\"=\" * 40)\n",
    "# Note: Zero_division=0 handles classes that might not appear in validation set\n",
    "print(classification_report(y_test_B, pred_b, zero_division=0))\n",
    "\n",
    "# Plot Confusion Matrix for B\n",
    "fig_b, ax_b = plt.subplots(figsize=(12, 12))\n",
    "cm_b = confusion_matrix(y_test_B, pred_b)\n",
    "# We don't list all 32 labels on axis to keep it clean, or we can just use default ints\n",
    "disp_b = ConfusionMatrixDisplay(confusion_matrix=cm_b)\n",
    "disp_b.plot(cmap=plt.cm.Greens, ax=ax_b, values_format=\"d\")  # 'd' for integers\n",
    "ax_b.set_title(\"Target B: Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# --- Target C (Regression 0-1) ---\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"TARGET C (Regression) PERFORMANCE\")\n",
    "print(\"=\" * 40)\n",
    "mae_c = mean_absolute_error(y_test_C, pred_c)\n",
    "print(f\"Mean Absolute Error (MAE): {mae_c:.4f}\")\n",
    "\n",
    "# Plot True vs Predicted\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test_C, pred_c, alpha=0.5, color=\"purple\", label=\"Predictions\")\n",
    "plt.plot([0, 1], [0, 1], \"r--\", linewidth=2, label=\"Ideal Perfect Prediction\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(f\"Target C: True vs Predicted (MAE={mae_c:.4f})\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ad304",
   "metadata": {},
   "source": [
    "# 5. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a78820",
   "metadata": {},
   "source": [
    "## 5.1.Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152a92a1",
   "metadata": {},
   "source": [
    "### 5.1. Experiment 1 Results: Learning Rate Analysis\n",
    "\n",
    "| Learning Rate | Total Val Loss | Target A (Acc) | Target B (Acc) | Target C (MAE) | Epochs Run |\n",
    "| :--- | :--- | :--- | :--- | :--- | :--- |\n",
    "| **0.01** | 5.3135 | 0.2593 | 0.0407 | **0.1972** | 50 |\n",
    "| **0.001** | **5.3018** | **0.2889** | **0.0519** | 0.2034 | 50 |\n",
    "| **0.0001** | 5.4751 | 0.2444 | 0.0407 | 0.2294 | 50 |\n",
    "\n",
    "**Observation:**\n",
    "* **Optimal Learning Rate:** **LR = 0.001** achieved the lowest Total Validation Loss (5.3018) and the highest Accuracy for both Target A (28.89%) and Target B (5.19%). This indicates it provides the best balance between convergence speed and stability.\n",
    "* **Comparison:** While LR = 0.01 performed well on the regression task (lowest MAE for Target C), its classification accuracy was lower than 0.001. Conversely, LR = 0.0001 resulted in the highest loss, suggesting it was too slow to converge within the given epochs.\n",
    "* **Conclusion:** We select **LR = 0.001** as the base learning rate for subsequent experiments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e67ed0",
   "metadata": {},
   "source": [
    "### 5.2. Experiment 2 Results: Scheduler Strategy Analysis\n",
    "\n",
    "| Strategy | Total Val Loss | Target A (Acc) | Target B (Acc) | Target C (MAE) | Epochs Run |\n",
    "| :--- | :--- | :--- | :--- | :--- | :--- |\n",
    "| **1. Fixed LR** (Baseline) | 5.4098 | 0.2667 | 0.0370 | 0.2180 | 43 |\n",
    "| **2. ReduceLR On Plateau** | **5.1996** | **0.3185** | **0.0519** | **0.1856** | **60** |\n",
    "\n",
    "**Observation:**\n",
    "* **Performance Superiority:** The **ReduceLROnPlateau** strategy consistently outperformed the Fixed LR baseline across all metrics. Most notably, Target A Accuracy improved by approximately **5.2%** (from 26.67% to 31.85%), and Target C MAE was significantly reduced to **0.1856**.\n",
    "* **Convergence Behavior:** The Fixed LR strategy stagnated early, triggering Early Stopping at epoch 43. In contrast, the Scheduler allowed the model to continue training for **60 epochs**, dynamically lowering the learning rate to escape local minima and fine-tune the weights for better generalization.\n",
    "* **Conclusion:** Based on these results, we will incorporate the `ReduceLROnPlateau` scheduler into the final model training to ensure optimal convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b40c3",
   "metadata": {},
   "source": [
    "### 5.3.Ablations Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac4bbd4",
   "metadata": {},
   "source": [
    "| Loss Function                     | Accuracy | Precision | Recall | F1-score |\n",
    "|----------------------------------|----------|-----------|--------|----------|\n",
    "| Sparse Categorical Crossentropy | 0.37     | 0.37      | 0.36   | 0.35     |\n",
    "| Sparse Categorical Crossentropy | 0.05     | 0.04      | 0.05   | 0.03     |\n",
    "| Mean Squared Error (MSE)        | N/A      | N/A       | N/A    | N/A      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31949b9f",
   "metadata": {},
   "source": [
    "| Optimizer | Accuracy | Precision | Recall | F1-score |\n",
    "|-----------|----------|-----------|--------|----------|\n",
    "| Adam | 0.37 | 0.37 | 0.36 | 0.35 |\n",
    "| Adam | 0.05 | 0.04 | 0.05 | 0.03 |\n",
    "| Adam | N/A  | N/A  | N/A  | N/A  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159b0ba",
   "metadata": {},
   "source": [
    "# 6. Evaluation & discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f01248",
   "metadata": {},
   "source": [
    "# 7. Reflection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
